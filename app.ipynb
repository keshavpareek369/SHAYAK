{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load keys from .env file if available\n",
    "load_dotenv()\n",
    "\n",
    "# --------------------------\n",
    "# CONFIGURATION\n",
    "# --------------------------\n",
    "JSON_PATH = \"D:/gov-scheme-assistant-updated/threetry/schemes.json\"\n",
    "DB_DIR = \"rag_db\"\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # lightweight & fast\n",
    "\n",
    "# --------------------------\n",
    "# STEP 1: LOAD AND PARSE JSON\n",
    "# --------------------------\n",
    "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "docs = []\n",
    "for entry in data:\n",
    "    kb = entry[\"knowledge_base_entry\"]\n",
    "    text_parts = []\n",
    "\n",
    "    # Main fields\n",
    "    text_parts.append(f\"Scheme: {kb.get('scheme', '')}\")\n",
    "    text_parts.append(f\"Summary: {kb.get('summary', '')}\")\n",
    "\n",
    "    # Flatten nested fields (key_information, all_extracted_sections, etc.)\n",
    "    for section in [\"key_information\", \"all_extracted_sections\"]:\n",
    "        section_data = kb.get(section, {})\n",
    "        if isinstance(section_data, dict):\n",
    "            for key, value in section_data.items():\n",
    "                if isinstance(value, list):\n",
    "                    text_parts.extend(value)\n",
    "                elif isinstance(value, str):\n",
    "                    text_parts.append(value)\n",
    "\n",
    "    # Combine all text\n",
    "    full_text = \"\\n\".join(text_parts).strip()\n",
    "\n",
    "    # Create Document for embedding\n",
    "    if full_text:\n",
    "        docs.append(Document(page_content=full_text, metadata={\"scheme\": kb.get(\"scheme\", \"Unknown\")}))\n",
    "\n",
    "print(f\"Loaded {len(docs)} documents.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
