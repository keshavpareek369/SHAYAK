{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244be6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader.py\n",
    "import requests\n",
    "\n",
    "BASE_URL = \"https://www.myscheme.gov.in/api/v2/scheme/search\"\n",
    "\n",
    "def fetch_schemes(query: str, limit: int = 10):\n",
    "    params = {\"q\": query, \"limit\": limit}\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"schemes\", [])\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62968e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever.py\n",
    "from langchain.schema import Document\n",
    "\n",
    "def get_scheme_docs(query: str):\n",
    "    schemes = fetch_schemes(query)\n",
    "    docs = []\n",
    "    for s in schemes:\n",
    "        title = s.get(\"title\", \"No Title\")\n",
    "        desc = s.get(\"shortDesc\", \"\")\n",
    "        url = f\"https://www.myscheme.gov.in/schemes/{s.get('schemeId')}\"\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=f\"{title}\\n{desc}\\nMore info: {url}\",\n",
    "                metadata={\"source\": url}\n",
    "            )\n",
    "        )\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb97d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "# from retriever import get_scheme_docs   # keep if you have retriever.py\n",
    "\n",
    "def build_chatbot(query: str):\n",
    "    docs = get_scheme_docs(query)\n",
    "\n",
    "    # ✅ HuggingFace embeddings\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    # ✅ Chroma VectorDB (with persistence option)\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=\"./chroma_db\"   # folder to save db\n",
    "    )\n",
    "    retriever = vectordb.as_retriever()\n",
    "\n",
    "    # ✅ HuggingFace LLM (Flan-T5 as example)\n",
    "    hf_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", max_length=512)\n",
    "    llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "\n",
    "    # ✅ RetrievalQA chain\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "    return qa_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac29d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "# from chatbot import build_chatbot\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"education loan schemes\"\n",
    "    chatbot = build_chatbot(query)\n",
    "    result = chatbot.run(\"Tell me about available education loan schemes?\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE_URL = \"https://www.myscheme.gov.in/search\"\n",
    "\n",
    "def scrape_schemes(query: str, limit: int = 5):\n",
    "    params = {\"q\": query}\n",
    "    response = requests.get(BASE_URL, params=params, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error:\", response.status_code)\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    schemes = []\n",
    "\n",
    "    # Each scheme card is inside <a href=\"/schemes/...\">\n",
    "    for card in soup.select(\"a[href^='/schemes']\")[:limit]:\n",
    "        title = card.select_one(\"h2, h3\")\n",
    "        desc = card.select_one(\"p\")\n",
    "        schemes.append({\n",
    "            \"title\": title.text.strip() if title else None,\n",
    "            \"description\": desc.text.strip() if desc else None,\n",
    "            \"url\": \"https://www.myscheme.gov.in\" + card[\"href\"]\n",
    "        })\n",
    "    return schemes\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    schemes = scrape_schemes(\"education\", limit=5)\n",
    "    for s in schemes:\n",
    "        print(f\"\\nTitle: {s['title']}\\nDescription: {s['description']}\\nURL: {s['url']}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
